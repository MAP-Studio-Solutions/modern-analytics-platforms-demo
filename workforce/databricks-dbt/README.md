# ğŸ“˜ Workforce Analytics â€” dbtâ€‘Databricks Method

This folder contains the **dbtâ€‘Databricks implementation** of the Workforce Analytics domain.  
It demonstrates how this domain is executed using:

- dbt models (staging â†’ intermediate â†’ marts)
- dbt sources + schema.yml metadata
- dbt tests (unique, not_null, relationships)
- dbt snapshots for SCD Type 2
- dbt DAGâ€‘driven execution
- Databricks SQL warehouse or cluster as the execution engine

This README explains:

- what documents exist  
- which ones are actually used at runtime  
- how the dbt execution architecture works  
- how data flows from raw â†’ staging â†’ intermediate â†’ marts  

---

## 1. Repository Layout (Methodâ€‘Specific)

```
workforce/
  dbt-databricks/
    README.md                â† You are here
    models/
      staging/               â† Source staging models (stg_*)
      intermediate/          â† SCD2 + PIT logic (int_*)
      marts/                 â† Dimensional + reporting models (dim_*, fct_*)
    snapshots/               â† dbt snapshots for SCD2
    seeds/                   â† Optional static reference data
    macros/                  â† Reusable SQL macros
    tests/                   â† Custom tests (if any)
    dbt_project.yml          â† dbt project configuration
    packages.yml             â† External dbt packages
  ingestion/
    config/
      sources.yaml           â† Runtime metadata input (optional for dbt)
  docs/                      â† Human documentation (not executed)
```

---

## 2. What Documents Are Actually Used at Runtime

| Document | Used By | Purpose |
|---------|---------|---------|
| `dbt_project.yml` | dbt CLI / dbt Cloud | Defines project structure, model paths, configs |
| `models/**/*.sql` | dbt | SQL transformations for staging, intermediate, marts |
| `models/**/*.yml` | dbt | Sources, tests, documentation |
| `snapshots/*.sql` | dbt | SCD Type 2 change tracking |
| `packages.yml` | dbt | External packages (dbt-utils, dbt-labs packages) |
| `macros/*.sql` | dbt | Reusable SQL logic |
| `seeds/*.csv` | dbt | Static reference data |
| `sources.yaml` | Optional | Can be used to generate dbt sources dynamically |
| `docs/*.md` | Humans only | Architecture, modeling, explanations |

Everything else is scaffolding.

---

## 3. Execution Architecture (dbtâ€‘Databricks)

This method uses **dbtâ€™s DAGâ€‘driven SQL execution**, orchestrated by:

- dbt CLI  
- dbt Cloud  
- or Databricks Workflows calling `dbt run`  

### Highâ€‘Level Flow

```
dbt sources
    â†“
staging models (stg_*)
    â†“
intermediate models (int_*)
    â†“
snapshots (SCD2)
    â†“
marts (dim_*, fct_*)
```

dbt handles:

- dependency resolution  
- ordering  
- testing  
- documentation  
- incremental logic  
- snapshotting  

---

## 4. Detailed Flow Diagram

### 1. Source Definitions

```
models/staging/sources.yml
   â””â”€â”€ defines:
         - raw tables
         - column descriptions
         - freshness tests
         - source-level constraints
```

### 2. Staging Layer (stg_*)

```
stg_employees.sql
   â””â”€â”€ Clean + standardize raw data
   â””â”€â”€ Rename columns to canonical naming
   â””â”€â”€ Apply type casting
   â””â”€â”€ Apply light business rules
```

### 3. Intermediate Layer (int_*)

```
int_employees_scd2.sql
   â””â”€â”€ Apply SCD Type 2 logic
   â””â”€â”€ Use dbt snapshots or custom SQL
   â””â”€â”€ Build point-in-time reconstruction tables
```

### 4. Snapshots (SCD2)

```
snapshots/employees_snapshot.sql
   â””â”€â”€ Tracks changes over time
   â””â”€â”€ Maintains valid_from / valid_to windows
   â””â”€â”€ Drives SCD2 logic for downstream models
```

### 5. Marts Layer (dim_*, fct_*)

```
dim_employee.sql
   â””â”€â”€ Surrogate keys
   â””â”€â”€ Slowly changing dimensions
   â””â”€â”€ Conformed dimensions

fct_headcount.sql
   â””â”€â”€ Fact tables
   â””â”€â”€ Metrics + aggregations
   â””â”€â”€ Joins to dimensions
```

---

## 5. Document Explanations

### `dbt_project.yml`  
Defines the dbt project structure, model paths, and configs.

### `models/staging/*.sql`  
Implements raw â†’ staging transformations.

### `models/intermediate/*.sql`  
Implements SCD2, PIT logic, and intermediate transformations.

### `models/marts/*.sql`  
Implements dimensional models and fact tables.

### `models/**/*.yml`  
Defines sources, tests, and documentation.

### `snapshots/*.sql`  
Implements SCD Type 2 change tracking.

### `macros/*.sql`  
Reusable SQL logic for transformations.

### `seeds/*.csv`  
Static reference data loaded via `dbt seed`.

### `docs/*.md`  
Humanâ€‘readable explanations.  
Not used by code.

---

## 6. Why This README Matters

Each **method** (Databricksâ€‘native, dbt, Genie) has a different execution architecture:

- Databricksâ€‘native â†’ SQLâ€‘first, orchestrated by Workflows  
- dbt â†’ modelâ€‘first, DAGâ€‘driven, with tests + snapshots  
- Genie â†’ semanticâ€‘layerâ€‘first, AIâ€‘assisted querying  

This README ensures the **method folder** explains:

- what is executed  
- what is configuration  
- what is documentation  
- how the flow works endâ€‘toâ€‘end  

So when someone opens the folder, they immediately understand:

**â€œHow does this method actually run?â€**
